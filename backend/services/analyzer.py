# backend/services/analyzer.py
import os
import json
from typing import List, Dict, Tuple
import pandas as pd

import re

# ---------- Heuristic fallback (ƒë∆°n gi·∫£n, ƒë·ªß ch·∫°y khi kh√¥ng c√≥ API key) ----------
CRIT_KWS = ["kernel panic", "panic:", "segfault", "oops", "oom-killer", "out of memory"]
WARN_KWS = ["error", "failed", "timeout", "retry", "throttle", "denied"]

def _heuristic_analyze(logs):
    out = []
    for i, log in enumerate(logs, 1):
        s = str(log).lower()
        if any(k in s for k in CRIT_KWS):
            level = "CRITICAL"
            summary = "Critical system error detected."
            suggestion = "Inspect system immediately (dmesg/syslog), mitigate impact."
        elif any(k in s for k in WARN_KWS):
            level = "WARNING"
            summary = "Warning/error observed."
            suggestion = "Investigate root cause; check recent changes/hardware."
        else:
            level = "INFO"
            summary = "No critical anomaly."
            suggestion = "No action."
        out.append({"log_index": i, "level": level, "summary": summary, "suggestion": suggestion})
    return out

# ---------- OpenAI client factory (SDK v1.x). KH√îNG truy·ªÅn proxies= v√†o OpenAI(...) ----------
def _make_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return None
    try:
        from openai import OpenAI
        import httpx
        proxy = (os.getenv("HTTPS_PROXY") or os.getenv("HTTP_PROXY")
                 or os.getenv("https_proxy") or os.getenv("http_proxy"))
        if proxy:
            http_client = httpx.Client(proxies=proxy, timeout=30.0)
            return OpenAI(api_key=api_key, http_client=http_client)
        return OpenAI(api_key=api_key)
    except Exception as e:
        print(f"‚ö†Ô∏è Cannot construct OpenAI client: {e}")
        return None

# ---------- H√ÄM CH√çNH: g·ªçi AI, tr·∫£ items ----------
def analyze_logs_with_openai(logs):
    """
    Input:  logs -> list[str] (m·ªói ph·∫ßn t·ª≠ l√† 1 d√≤ng log ƒë√£ chu·∫©n ho√°)
    Output: (items, used_openai: bool)
            items = [{log_index, level, summary, suggestion}, ...]
    """
    # Tr∆∞·ªùng h·ª£p kh√¥ng c√≥ d·ªØ li·ªáu
    if not logs:
        return ([], False)

    client = _make_openai_client()
    if client is None:
        print("üîé OPENAI_API_KEY missing or client init failed ‚Üí heuristic.")
        return (_heuristic_analyze(logs), False)

    try:
        # ƒê√°nh s·ªë ƒë·ªÉ model refer ƒë√∫ng d√≤ng
        numbered = [f"Log {i+1}: {t}" for i, t in enumerate(logs)]

        schema = {
            "name": "log_array",
            "schema": {
                "type": "object",
                "properties": {
                    "items": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "log_index":  {"type": "integer"},
                                "level":      {"type": "string", "enum": ["INFO","WARNING","CRITICAL"]},
                                "summary":    {"type": "string"},
                                "suggestion": {"type": "string"}
                            },
                            "required": ["log_index","level","summary","suggestion"],
                            "additionalProperties": False
                        }
                    }
                },
                "required": ["items"],
                "additionalProperties": False
            }
        }

        prompt = (
            "You are a security analyst. For each log line, classify severity (INFO|WARNING|CRITICAL), "
            "write a short summary (with port) and a concrete suggestion. Respond ONLY with JSON matching the schema.\n\n"
            + "\n".join(numbered)
        )

        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            response_format={"type": "json_schema", "json_schema": schema},
        )

        content = resp.choices[0].message.content
        # Parse JSON an to√†n (n·∫øu c√≥ r√°c tr·∫Øng)
        try:
            data = json.loads(content)
        except Exception:
            # fallback: c·ªë l·∫•y ph·∫ßn {...} l·ªõn nh·∫•t
            start = content.find("{")
            end = content.rfind("}")
            data = json.loads(content[start:end+1])

        items = data.get("items", [])
        # B·∫£o v·ªá: n·∫øu model tr·∫£ thi·∫øu/sai, t·ª± s·ª≠a ƒë·ªÉ kh√¥ng v·ª° pipeline
        if not isinstance(items, list) or not items:
            items = []
        # ƒê·∫£m b·∫£o log_index t·ªìn t·∫°i & ƒë√∫ng range 1..N
        n = len(logs)
        fixed = []
        for i, it in enumerate(items or []):
            try:
                idx = int(it.get("log_index", i+1))
            except Exception:
                idx = i + 1
            if idx < 1 or idx > n:
                idx = i + 1
            level = str(it.get("level","INFO")).upper()
            if level not in ("INFO","WARNING","CRITICAL"):
                level = "INFO"
            fixed.append({
                "log_index": idx,
                "level": level,
                "summary": it.get("summary") or "No critical anomaly.",
                "suggestion": it.get("suggestion") or "No action."
            })

        # N·∫øu sau khi fix v·∫´n r·ªóng (model l·ªói), d√πng heuristic
        if not fixed:
            fixed = _heuristic_analyze(logs)

        return (fixed, True)

    except Exception as e:
        print(f"‚ö†Ô∏è OpenAI call failed ‚Üí heuristic. Error: {e}")
        return (_heuristic_analyze(logs), False)


def summarize_levels(results: List[Dict]) -> Dict[str, int]:
    ser = pd.Series([r["level"] for r in results])
    counts = ser.value_counts().to_dict()
    return counts


def build_detailed_prompt_from_alert(alert: Dict) -> str:
    """
    Build a detailed Vietnamese prompt from raw anomaly alert with context.
    """
    alert_type = alert.get("type", "unknown")
    subject = alert.get("subject", "N/A")
    text = alert.get("text", "")
    ctx = alert.get("prompt_ctx", {})
    
    user = ctx.get("user")
    group = ctx.get("group")
    behavior = ctx.get("behavior", {})
    time_str = ctx.get("time")
    baseline = ctx.get("baseline", {})
    evidence = alert.get("evidence", {})
    
    prompt = "Ph√¢n t√≠ch s·ª± ki·ªán b·∫•t th∆∞·ªùng sau:\n\n"
    
    if user:
        prompt += f"- Ng∆∞·ªùi d√πng: {user}"
        if group:
            prompt += f" (Ph√≤ng ban: {group})"
        prompt += "\n"
    
    # Chi ti·∫øt h√†nh vi theo lo·∫°i
    if alert_type == "new_user":
        events = evidence.get("events", 0)
        prompt += f"- H√†nh vi: Ng∆∞·ªùi d√πng M·ªöI xu·∫•t hi·ªán trong h·ªá th·ªëng v·ªõi {events} s·ª± ki·ªán.\n"
    elif alert_type == "foreign_country_access":
        countries = evidence.get("countries", [])
        events = evidence.get("events", 0)
        prompt += f"- H√†nh vi: Truy c·∫≠p t·ª´ c√°c qu·ªëc gia n∆∞·ªõc ngo√†i: {', '.join(countries)} ({events} s·ª± ki·ªán).\n"
    elif alert_type == "off_hours_access":
        hours = evidence.get("hours", [])
        events = evidence.get("events", 0)
        prompt += f"- H√†nh vi: Truy c·∫≠p ngo√†i gi·ªù l√†m vi·ªác v√†o l√∫c {hours}h ({events} s·ª± ki·ªán).\n"
    
    if time_str:
        prompt += f"- Th·ªùi gian: {time_str}.\n"
    
    # Baseline info
    if baseline:
        if alert_type == "new_user":
            prompt += f"- D·ªØ li·ªáu c∆° s·ªü: Ng∆∞·ªùi d√πng kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng qu·∫£n l√Ω.\n"
        elif alert_type == "off_hours_access":
            working_hours = baseline.get("working_hours", "6h-22h")
            prompt += f"- D·ªØ li·ªáu c∆° s·ªü: Gi·ªù l√†m vi·ªác b√¨nh th∆∞·ªùng l√† {working_hours}.\n"
        elif alert_type == "foreign_country_access":
            prompt += f"- D·ªØ li·ªáu c∆° s·ªü: Ng∆∞·ªùi d√πng th∆∞·ªùng ch·ªâ truy c·∫≠p t·ª´ Vi·ªát Nam.\n"
    
    # Risk score
    severity = alert.get("severity", "WARNING")
    score = alert.get("score", 0)
    prompt += f"- M·ª©c ƒë·ªô c·∫£nh b√°o: {severity} (ƒêi·ªÉm: {score:.1f}).\n"
    
    prompt += (
        "\nY√™u c·∫ßu ph√¢n t√≠ch:\n"
        "1. T√≥m t·∫Øt s·ª± ki·ªán m·ªôt c√°ch s√∫c t√≠ch.\n"
        "2. Li·ªát k√™ c√°c ch·ªâ s·ªë r·ªßi ro ti·ªÅm ·∫©n.\n"
        "3. ƒê√°nh gi√° m·ª©c ƒë·ªô r·ªßi ro (Th·∫•p/Trung b√¨nh/Cao/C·ª±c k·ª≥ nguy c·∫•p).\n"
        "4. ƒê·ªÅ xu·∫•t h√†nh ƒë·ªông c·ª• th·ªÉ (Gi√°m s√°t th√™m, X√°c minh danh t√≠nh, T·∫°m kh√≥a t√†i kho·∫£n, v.v.).\n"
        "Tr·∫£ l·ªùi CH·ªà b·∫±ng JSON."
    )
    
    return prompt


def analyze_alert_prompt(prompt: str) -> Tuple[Dict, bool]:
    """
    Given a detailed Vietnamese prompt for a single alert, ask the model to return structured risk analysis.
    Output: ({summary, risks, risk_level, actions}, used_openai)
    """
    client = _make_openai_client()
    if client is None:
        # Heuristic fallback
        return ({
            "summary": "Kh√¥ng th·ªÉ g·ªçi AI. ƒê·ªÅ xu·∫•t gi√°m s√°t th√™m.",
            "risks": ["Thi·∫øu ng·ªØ c·∫£nh m√¥ h√¨nh"],
            "risk_level": "Trung b√¨nh",
            "actions": ["Gi√°m s√°t th√™m"],
        }, False)

    schema = {
        "name": "risk_report",
        "schema": {
            "type": "object",
            "properties": {
                "summary": {"type": "string"},
                "risks": {"type": "array", "items": {"type": "string"}},
                "risk_level": {"type": "string", "enum": ["Th·∫•p","Trung b√¨nh","Cao","C·ª±c k·ª≥ nguy c·∫•p"]},
                "actions": {"type": "array", "items": {"type": "string"}},
            },
            "required": ["summary","risks","risk_level","actions"],
            "additionalProperties": False,
        }
    }

    msg = (
        prompt
        + "\n\nH√£y tr·∫£ l·ªùi CH·ªà b·∫±ng JSON ƒë√∫ng schema."
    )
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": msg}],
            temperature=0,
            response_format={"type": "json_schema", "json_schema": schema},
        )
        content = resp.choices[0].message.content
        import json
        try:
            data = json.loads(content)
        except Exception:
            start = content.find("{")
            end = content.rfind("}")
            data = json.loads(content[start:end+1])
        return (data, True)
    except Exception as e:
        print(f"‚ö†Ô∏è analyze_alert_prompt failed: {e}")
        return ({
            "summary": "L·ªói khi g·ªçi AI.",
            "risks": ["Kh√¥ng ph√¢n t√≠ch ƒë∆∞·ª£c"],
            "risk_level": "Trung b√¨nh",
            "actions": ["Gi√°m s√°t th√™m"],
        }, False)